{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hKfvNlxGgDtB"
      },
      "source": [
        "# Installing libraries\n",
        "\n",
        "Installing HuggingFace Transformers (https://github.com/huggingface/transformers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: datasets in /home/orian/PycharmProjects/ANLP/venv/lib/python3.10/site-packages (2.20.0)\n",
            "Requirement already satisfied: transformers in /home/orian/PycharmProjects/ANLP/venv/lib/python3.10/site-packages (4.41.2)\n",
            "Requirement already satisfied: scikit-learn in /home/orian/PycharmProjects/ANLP/venv/lib/python3.10/site-packages (1.5.1)\n",
            "Requirement already satisfied: torch in /home/orian/PycharmProjects/ANLP/venv/lib/python3.10/site-packages (2.3.0+cu121)\n",
            "Requirement already satisfied: pandas in /home/orian/PycharmProjects/ANLP/venv/lib/python3.10/site-packages (2.2.2)\n",
            "Requirement already satisfied: evaluate in /home/orian/PycharmProjects/ANLP/venv/lib/python3.10/site-packages (0.4.2)\n",
            "Requirement already satisfied: tensorboardX in /home/orian/PycharmProjects/ANLP/venv/lib/python3.10/site-packages (2.6.2.2)\n",
            "Requirement already satisfied: filelock in /home/orian/PycharmProjects/ANLP/venv/lib/python3.10/site-packages (from datasets) (3.13.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /home/orian/PycharmProjects/ANLP/venv/lib/python3.10/site-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /home/orian/PycharmProjects/ANLP/venv/lib/python3.10/site-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: pyarrow-hotfix in /home/orian/PycharmProjects/ANLP/venv/lib/python3.10/site-packages (from datasets) (0.6)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /home/orian/PycharmProjects/ANLP/venv/lib/python3.10/site-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: requests>=2.32.2 in /home/orian/PycharmProjects/ANLP/venv/lib/python3.10/site-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /home/orian/PycharmProjects/ANLP/venv/lib/python3.10/site-packages (from datasets) (4.66.4)\n",
            "Requirement already satisfied: xxhash in /home/orian/PycharmProjects/ANLP/venv/lib/python3.10/site-packages (from datasets) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /home/orian/PycharmProjects/ANLP/venv/lib/python3.10/site-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.5.0,>=2023.1.0 in /home/orian/PycharmProjects/ANLP/venv/lib/python3.10/site-packages (from fsspec[http]<=2024.5.0,>=2023.1.0->datasets) (2024.2.0)\n",
            "Requirement already satisfied: aiohttp in /home/orian/PycharmProjects/ANLP/venv/lib/python3.10/site-packages (from datasets) (3.9.5)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.2 in /home/orian/PycharmProjects/ANLP/venv/lib/python3.10/site-packages (from datasets) (0.23.2)\n",
            "Requirement already satisfied: packaging in /home/orian/PycharmProjects/ANLP/venv/lib/python3.10/site-packages (from datasets) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /home/orian/PycharmProjects/ANLP/venv/lib/python3.10/site-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /home/orian/PycharmProjects/ANLP/venv/lib/python3.10/site-packages (from transformers) (2024.5.15)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /home/orian/PycharmProjects/ANLP/venv/lib/python3.10/site-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /home/orian/PycharmProjects/ANLP/venv/lib/python3.10/site-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /home/orian/PycharmProjects/ANLP/venv/lib/python3.10/site-packages (from scikit-learn) (1.14.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /home/orian/PycharmProjects/ANLP/venv/lib/python3.10/site-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/orian/PycharmProjects/ANLP/venv/lib/python3.10/site-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /home/orian/PycharmProjects/ANLP/venv/lib/python3.10/site-packages (from torch) (4.9.0)\n",
            "Requirement already satisfied: sympy in /home/orian/PycharmProjects/ANLP/venv/lib/python3.10/site-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /home/orian/PycharmProjects/ANLP/venv/lib/python3.10/site-packages (from torch) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /home/orian/PycharmProjects/ANLP/venv/lib/python3.10/site-packages (from torch) (3.1.3)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/orian/PycharmProjects/ANLP/venv/lib/python3.10/site-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/orian/PycharmProjects/ANLP/venv/lib/python3.10/site-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/orian/PycharmProjects/ANLP/venv/lib/python3.10/site-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/orian/PycharmProjects/ANLP/venv/lib/python3.10/site-packages (from torch) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/orian/PycharmProjects/ANLP/venv/lib/python3.10/site-packages (from torch) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/orian/PycharmProjects/ANLP/venv/lib/python3.10/site-packages (from torch) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/orian/PycharmProjects/ANLP/venv/lib/python3.10/site-packages (from torch) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/orian/PycharmProjects/ANLP/venv/lib/python3.10/site-packages (from torch) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/orian/PycharmProjects/ANLP/venv/lib/python3.10/site-packages (from torch) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /home/orian/PycharmProjects/ANLP/venv/lib/python3.10/site-packages (from torch) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/orian/PycharmProjects/ANLP/venv/lib/python3.10/site-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.0 in /home/orian/PycharmProjects/ANLP/venv/lib/python3.10/site-packages (from torch) (2.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/orian/PycharmProjects/ANLP/venv/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.1.105)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /home/orian/PycharmProjects/ANLP/venv/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /home/orian/PycharmProjects/ANLP/venv/lib/python3.10/site-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /home/orian/PycharmProjects/ANLP/venv/lib/python3.10/site-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: protobuf>=3.20 in /home/orian/PycharmProjects/ANLP/venv/lib/python3.10/site-packages (from tensorboardX) (4.25.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /home/orian/PycharmProjects/ANLP/venv/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /home/orian/PycharmProjects/ANLP/venv/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /home/orian/PycharmProjects/ANLP/venv/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /home/orian/PycharmProjects/ANLP/venv/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /home/orian/PycharmProjects/ANLP/venv/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /home/orian/PycharmProjects/ANLP/venv/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: six>=1.5 in /home/orian/PycharmProjects/ANLP/venv/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /home/orian/PycharmProjects/ANLP/venv/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /home/orian/PycharmProjects/ANLP/venv/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/orian/PycharmProjects/ANLP/venv/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (2.2.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/orian/PycharmProjects/ANLP/venv/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (2024.6.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /home/orian/PycharmProjects/ANLP/venv/lib/python3.10/site-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /home/orian/PycharmProjects/ANLP/venv/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.2\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets transformers scikit-learn torch pandas evaluate tensorboardX"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tRuKCDbpfQd7"
      },
      "source": [
        "# Dataset processing\n",
        "\n",
        "Uploading the dataset, splitting the data into train, validation and test sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "from pathlib import Path\n",
        "\n",
        "\n",
        "path = Path('../data/original.json')\n",
        "data = json.loads(path.read_text(encoding='utf-8'))\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "df1 = pd.DataFrame(df['data'].values.tolist())\n",
        "df1.columns = df1.columns\n",
        "col = df.columns.difference(['data'])\n",
        "df = pd.concat([df[col], df1],axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "data = df.explode('paragraphs')['paragraphs'].to_list()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ywVh-BXxfPAD"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "train, temp = train_test_split(data, test_size=0.3, shuffle=True)\n",
        "val, test = train_test_split(temp, test_size=0.5, shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VkXTOmn7gyee"
      },
      "source": [
        "Getting contexts, questions and answers from the train and validation sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Bqqh_4GtfQ44"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/orian/PycharmProjects/ANLP/venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import pickle\n",
        "from datasets import Dataset, DatasetDict\n",
        "\n",
        "def read_set(set):\n",
        "    results = []\n",
        "\n",
        "    for group in set:\n",
        "        context = group['context']\n",
        "        for qa in group['qas']:\n",
        "            question = qa['question']\n",
        "            results.append({\n",
        "                'question': question,\n",
        "                'context': context,\n",
        "                'is_impossible': qa['is_impossible'],\n",
        "                'answers': {\n",
        "                    'text': [a['text'] for a in qa['answers']],\n",
        "                    'answer_start': [a['answer_start'] for a in qa['answers'] if not qa['is_impossible']],\n",
        "                }\n",
        "            })\n",
        "\n",
        "    return results\n",
        "\n",
        "results_train = read_set(train)\n",
        "results_val = read_set(val)\n",
        "\n",
        "squad = DatasetDict(\n",
        "    {'train': Dataset.from_list(results_train).shuffle(),\n",
        "     'validation': Dataset.from_list(results_val).shuffle()\n",
        "     })\n",
        "\n",
        "\n",
        "with open(\"../data/squad_dataset.pkl\",\"wb\") as file:\n",
        "    pickle.dump(squad, file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "def prepare_train_features(examples):\n",
        "    # Tokenize our examples with truncation and padding, but keep the overflows using a stride.\n",
        "    # This results in one example possible giving several features when a context is long,\n",
        "    # each of those features having a context that overlaps a bit the context of the previous feature.\n",
        "    tokenized_examples = tokenizer(\n",
        "        examples[\"question\"],\n",
        "        examples[\"context\"],\n",
        "        truncation=\"only_second\",  # truncate context, not the question\n",
        "        max_length=512,\n",
        "        stride=128,\n",
        "        return_overflowing_tokens=True,\n",
        "        return_offsets_mapping=True,\n",
        "        padding=\"max_length\",\n",
        "    )\n",
        "\n",
        "    # Since one example might give us several features if it has a long context, we need a map from a feature to\n",
        "    # its corresponding example. This key gives us just that.\n",
        "    sample_mapping = tokenized_examples.pop(\"overflow_to_sample_mapping\")\n",
        "    # The offset mappings will give us a map from token to character position in the original context.\n",
        "    # This will help us compute the start_positions and end_positions.\n",
        "    offset_mapping = tokenized_examples.pop(\"offset_mapping\")\n",
        "\n",
        "    # Let's label those examples!\n",
        "    tokenized_examples[\"start_positions\"] = []\n",
        "    tokenized_examples[\"end_positions\"] = []\n",
        "\n",
        "    for i, offsets in enumerate(offset_mapping):\n",
        "        # We will label impossible answers with the index of the CLS token.\n",
        "        input_ids = tokenized_examples[\"input_ids\"][i]\n",
        "        cls_index = input_ids.index(tokenizer.cls_token_id)\n",
        "\n",
        "        # Grab the sequence corresponding to that example (to know what is the context and what is the question).\n",
        "        sequence_ids = tokenized_examples.sequence_ids(i)\n",
        "\n",
        "        # One example can give several spans, this is the index of the example containing this span of text.\n",
        "        sample_index = sample_mapping[i]\n",
        "        answers = examples[\"answers\"][sample_index]\n",
        "        # If no answers are given, set the cls_index as answer.\n",
        "        if len(answers[\"answer_start\"]) == 0:\n",
        "            tokenized_examples[\"start_positions\"].append(cls_index)\n",
        "            tokenized_examples[\"end_positions\"].append(cls_index)\n",
        "        else:\n",
        "            # Start/end character index of the answer in the text.\n",
        "            start_char = answers[\"answer_start\"][0]\n",
        "            end_char = start_char + len(answers[\"text\"][0])\n",
        "\n",
        "            # Start token index of the current span in the text.\n",
        "            token_start_index = 0\n",
        "            while sequence_ids[token_start_index] != 1:\n",
        "                token_start_index += 1\n",
        "\n",
        "            # End token index of the current span in the text.\n",
        "            token_end_index = len(input_ids) - 1\n",
        "            while sequence_ids[token_end_index] != 1:\n",
        "                token_end_index -= 1\n",
        "\n",
        "            # Detect if the answer is out of the span (in which case this feature is labeled with the CLS index).\n",
        "            if not (offsets[token_start_index][0] <= start_char and offsets[token_end_index][1] >= end_char):\n",
        "                tokenized_examples[\"start_positions\"].append(cls_index)\n",
        "                tokenized_examples[\"end_positions\"].append(cls_index)\n",
        "            else:\n",
        "                # Otherwise move the token_start_index and token_end_index to the two ends of the answer.\n",
        "                # Note: we could go after the last offset if the answer is the last word (edge case).\n",
        "                while token_start_index < len(offsets) and offsets[token_start_index][0] <= start_char:\n",
        "                    token_start_index += 1\n",
        "                tokenized_examples[\"start_positions\"].append(token_start_index - 1)\n",
        "                while offsets[token_end_index][1] >= end_char:\n",
        "                    token_end_index -= 1\n",
        "                tokenized_examples[\"end_positions\"].append(token_end_index + 1)\n",
        "\n",
        "    return tokenized_examples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Map: 100%|██████████| 2901/2901 [00:00<00:00, 7310.06 examples/s]\n",
            "Map: 100%|██████████| 643/643 [00:00<00:00, 7535.56 examples/s]\n",
            "/home/orian/PycharmProjects/ANLP/venv/lib/python3.10/site-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 3.0357, 'grad_norm': 65.25616455078125, 'learning_rate': 2.9482936918304035e-05, 'epoch': 0.1723543605653223}\n",
            "{'loss': 2.6153, 'grad_norm': 70.35901641845703, 'learning_rate': 2.896587383660807e-05, 'epoch': 0.3447087211306446}\n",
            "{'loss': 2.3928, 'grad_norm': 558.8857421875, 'learning_rate': 2.8448810754912102e-05, 'epoch': 0.5170630816959669}\n",
            "{'loss': 2.2951, 'grad_norm': 2.0668370723724365, 'learning_rate': 2.7931747673216133e-05, 'epoch': 0.6894174422612892}\n",
            "{'loss': 2.2593, 'grad_norm': 92.15816497802734, 'learning_rate': 2.7414684591520166e-05, 'epoch': 0.8617718028266115}\n",
            "{'eval_loss': 2.5154480934143066, 'eval_runtime': 3.5965, 'eval_samples_per_second': 178.785, 'eval_steps_per_second': 178.785, 'epoch': 1.0}\n",
            "{'loss': 2.0999, 'grad_norm': 99.86711883544922, 'learning_rate': 2.68976215098242e-05, 'epoch': 1.0341261633919339}\n",
            "{'loss': 2.0053, 'grad_norm': 86.7258071899414, 'learning_rate': 2.638055842812823e-05, 'epoch': 1.206480523957256}\n",
            "{'loss': 2.1228, 'grad_norm': 105.10668182373047, 'learning_rate': 2.5863495346432264e-05, 'epoch': 1.3788348845225784}\n",
            "{'loss': 1.9805, 'grad_norm': 16.653867721557617, 'learning_rate': 2.5346432264736298e-05, 'epoch': 1.5511892450879006}\n",
            "{'loss': 1.9624, 'grad_norm': 76.7372817993164, 'learning_rate': 2.4829369183040332e-05, 'epoch': 1.723543605653223}\n",
            "{'loss': 2.0112, 'grad_norm': 0.12495370209217072, 'learning_rate': 2.4312306101344366e-05, 'epoch': 1.8958979662185453}\n",
            "{'eval_loss': 2.5914087295532227, 'eval_runtime': 3.5831, 'eval_samples_per_second': 179.455, 'eval_steps_per_second': 179.455, 'epoch': 2.0}\n",
            "{'loss': 1.9238, 'grad_norm': 474.9012451171875, 'learning_rate': 2.3795243019648396e-05, 'epoch': 2.0682523267838677}\n",
            "{'loss': 1.6744, 'grad_norm': 57.13046646118164, 'learning_rate': 2.327817993795243e-05, 'epoch': 2.24060668734919}\n",
            "{'loss': 1.7344, 'grad_norm': 115.40227508544922, 'learning_rate': 2.2761116856256464e-05, 'epoch': 2.412961047914512}\n",
            "{'loss': 1.7957, 'grad_norm': 40.26581573486328, 'learning_rate': 2.2244053774560497e-05, 'epoch': 2.5853154084798344}\n",
            "{'loss': 1.934, 'grad_norm': 119.62785339355469, 'learning_rate': 2.172699069286453e-05, 'epoch': 2.757669769045157}\n",
            "{'loss': 1.7044, 'grad_norm': 11.461169242858887, 'learning_rate': 2.1209927611168565e-05, 'epoch': 2.930024129610479}\n",
            "{'eval_loss': 3.310353994369507, 'eval_runtime': 3.5577, 'eval_samples_per_second': 180.737, 'eval_steps_per_second': 180.737, 'epoch': 3.0}\n",
            "{'loss': 1.4028, 'grad_norm': 0.008772989735007286, 'learning_rate': 2.06928645294726e-05, 'epoch': 3.1023784901758016}\n",
            "{'loss': 1.3935, 'grad_norm': 31.963502883911133, 'learning_rate': 2.017580144777663e-05, 'epoch': 3.274732850741124}\n",
            "{'loss': 1.4255, 'grad_norm': 200.66217041015625, 'learning_rate': 1.965873836608066e-05, 'epoch': 3.447087211306446}\n",
            "{'loss': 1.3764, 'grad_norm': 0.006692417431622744, 'learning_rate': 1.9141675284384693e-05, 'epoch': 3.6194415718717683}\n",
            "{'loss': 1.4786, 'grad_norm': 74.35747528076172, 'learning_rate': 1.8624612202688727e-05, 'epoch': 3.7917959324370907}\n",
            "{'loss': 1.4163, 'grad_norm': 7.040789604187012, 'learning_rate': 1.810754912099276e-05, 'epoch': 3.964150293002413}\n",
            "{'eval_loss': 2.723491668701172, 'eval_runtime': 3.5678, 'eval_samples_per_second': 180.222, 'eval_steps_per_second': 180.222, 'epoch': 4.0}\n",
            "{'loss': 1.2171, 'grad_norm': 0.021117085590958595, 'learning_rate': 1.7590486039296795e-05, 'epoch': 4.1365046535677354}\n",
            "{'loss': 1.0356, 'grad_norm': 0.005110844969749451, 'learning_rate': 1.707342295760083e-05, 'epoch': 4.308859014133057}\n",
            "{'loss': 1.0874, 'grad_norm': 0.3150155246257782, 'learning_rate': 1.6556359875904862e-05, 'epoch': 4.48121337469838}\n",
            "{'loss': 1.1981, 'grad_norm': 0.005033937748521566, 'learning_rate': 1.6039296794208896e-05, 'epoch': 4.653567735263702}\n",
            "{'loss': 1.2149, 'grad_norm': 0.6071687340736389, 'learning_rate': 1.5522233712512926e-05, 'epoch': 4.825922095829024}\n",
            "{'loss': 1.1311, 'grad_norm': 6.592688083648682, 'learning_rate': 1.5005170630816959e-05, 'epoch': 4.998276456394347}\n",
            "{'eval_loss': 3.5699055194854736, 'eval_runtime': 3.3225, 'eval_samples_per_second': 193.528, 'eval_steps_per_second': 193.528, 'epoch': 5.0}\n",
            "{'loss': 0.7364, 'grad_norm': 0.0449274405837059, 'learning_rate': 1.4488107549120992e-05, 'epoch': 5.170630816959669}\n",
            "{'loss': 0.8793, 'grad_norm': 41.66160583496094, 'learning_rate': 1.3971044467425026e-05, 'epoch': 5.342985177524992}\n",
            "{'loss': 0.9927, 'grad_norm': 0.0012696891790255904, 'learning_rate': 1.345398138572906e-05, 'epoch': 5.515339538090314}\n",
            "{'loss': 0.8097, 'grad_norm': 164.09959411621094, 'learning_rate': 1.2936918304033094e-05, 'epoch': 5.6876938986556365}\n",
            "{'loss': 0.9503, 'grad_norm': 0.0010819330345839262, 'learning_rate': 1.2419855222337124e-05, 'epoch': 5.860048259220958}\n",
            "{'eval_loss': 5.099476337432861, 'eval_runtime': 3.3146, 'eval_samples_per_second': 193.992, 'eval_steps_per_second': 193.992, 'epoch': 6.0}\n",
            "{'loss': 0.8796, 'grad_norm': 0.00024060843861661851, 'learning_rate': 1.1902792140641158e-05, 'epoch': 6.03240261978628}\n",
            "{'loss': 0.5803, 'grad_norm': 8.199694275390357e-05, 'learning_rate': 1.1385729058945192e-05, 'epoch': 6.204756980351603}\n",
            "{'loss': 0.7067, 'grad_norm': 0.0001079047069652006, 'learning_rate': 1.0868665977249225e-05, 'epoch': 6.377111340916925}\n",
            "{'loss': 0.824, 'grad_norm': 227.82554626464844, 'learning_rate': 1.0351602895553258e-05, 'epoch': 6.549465701482248}\n",
            "{'loss': 0.6093, 'grad_norm': 0.001980461413040757, 'learning_rate': 9.834539813857291e-06, 'epoch': 6.72182006204757}\n",
            "{'loss': 0.7916, 'grad_norm': 0.04191938042640686, 'learning_rate': 9.317476732161323e-06, 'epoch': 6.894174422612892}\n",
            "{'eval_loss': 5.466240406036377, 'eval_runtime': 3.5866, 'eval_samples_per_second': 179.277, 'eval_steps_per_second': 179.277, 'epoch': 7.0}\n",
            "{'loss': 0.5755, 'grad_norm': 8.0328369140625, 'learning_rate': 8.800413650465357e-06, 'epoch': 7.066528783178215}\n",
            "{'loss': 0.431, 'grad_norm': 190.5584259033203, 'learning_rate': 8.28335056876939e-06, 'epoch': 7.238883143743537}\n",
            "{'loss': 0.5476, 'grad_norm': 19.77854347229004, 'learning_rate': 7.766287487073423e-06, 'epoch': 7.411237504308859}\n",
            "{'loss': 0.5464, 'grad_norm': 0.0004428208922035992, 'learning_rate': 7.249224405377457e-06, 'epoch': 7.583591864874181}\n",
            "{'loss': 0.5055, 'grad_norm': 252.8518829345703, 'learning_rate': 6.732161323681489e-06, 'epoch': 7.755946225439503}\n",
            "{'loss': 0.5259, 'grad_norm': 0.0018660201458260417, 'learning_rate': 6.215098241985523e-06, 'epoch': 7.928300586004826}\n",
            "{'eval_loss': 6.017505168914795, 'eval_runtime': 3.3178, 'eval_samples_per_second': 193.805, 'eval_steps_per_second': 193.805, 'epoch': 8.0}\n",
            "{'loss': 0.4173, 'grad_norm': 645.0370483398438, 'learning_rate': 5.698035160289556e-06, 'epoch': 8.100654946570149}\n",
            "{'loss': 0.2091, 'grad_norm': 0.011052229441702366, 'learning_rate': 5.180972078593589e-06, 'epoch': 8.273009307135471}\n",
            "{'loss': 0.3233, 'grad_norm': 0.03659144788980484, 'learning_rate': 4.6639089968976215e-06, 'epoch': 8.445363667700793}\n",
            "{'loss': 0.3448, 'grad_norm': 0.0017230968223884702, 'learning_rate': 4.146845915201655e-06, 'epoch': 8.617718028266115}\n",
            "{'loss': 0.3428, 'grad_norm': 9.28610610961914, 'learning_rate': 3.629782833505688e-06, 'epoch': 8.790072388831437}\n",
            "{'loss': 0.3466, 'grad_norm': 0.0004866068484261632, 'learning_rate': 3.1127197518097208e-06, 'epoch': 8.96242674939676}\n",
            "{'eval_loss': 6.768335819244385, 'eval_runtime': 3.3235, 'eval_samples_per_second': 193.468, 'eval_steps_per_second': 193.468, 'epoch': 9.0}\n",
            "{'loss': 0.2389, 'grad_norm': 141.37350463867188, 'learning_rate': 2.5956566701137537e-06, 'epoch': 9.134781109962082}\n",
            "{'loss': 0.2676, 'grad_norm': 32.94696044921875, 'learning_rate': 2.078593588417787e-06, 'epoch': 9.307135470527404}\n",
            "{'loss': 0.2866, 'grad_norm': 1.3544206619262695, 'learning_rate': 1.5615305067218202e-06, 'epoch': 9.479489831092726}\n",
            "{'loss': 0.1602, 'grad_norm': 0.0027423216961324215, 'learning_rate': 1.0444674250258532e-06, 'epoch': 9.651844191658048}\n",
            "{'loss': 0.1935, 'grad_norm': 0.02919601835310459, 'learning_rate': 5.274043433298862e-07, 'epoch': 9.824198552223372}\n",
            "{'loss': 0.227, 'grad_norm': 0.000438425486208871, 'learning_rate': 1.0341261633919339e-08, 'epoch': 9.996552912788694}\n",
            "{'eval_loss': 7.073003768920898, 'eval_runtime': 3.3694, 'eval_samples_per_second': 190.834, 'eval_steps_per_second': 190.834, 'epoch': 10.0}\n",
            "{'train_runtime': 1193.1967, 'train_samples_per_second': 24.313, 'train_steps_per_second': 24.313, 'train_loss': 1.1405871338287086, 'epoch': 10.0}\n",
            "model m-bert train time 0:19:53.289220\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 643/643 [00:01<00:00, 344.23it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "model m-bert invalid f1 score 0.9771807457160079\n",
            "model m-bert squad results {'exact': 21.15085536547434, 'f1': 47.424322555144975, 'total': 643, 'HasAns_exact': 21.15085536547434, 'HasAns_f1': 47.424322555144975, 'HasAns_total': 643, 'best_exact': 21.15085536547434, 'best_exact_thresh': 0.0, 'best_f1': 47.424322555144975, 'best_f1_thresh': 0.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Map: 100%|██████████| 2901/2901 [00:00<00:00, 9164.49 examples/s]\n",
            "Map: 100%|██████████| 643/643 [00:00<00:00, 8796.88 examples/s]\n",
            "/home/orian/PycharmProjects/ANLP/venv/lib/python3.10/site-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 3.3296, 'grad_norm': 20.72292137145996, 'learning_rate': 9.91382281971734e-06, 'epoch': 0.1723543605653223}\n",
            "{'loss': 2.7432, 'grad_norm': 31.193330764770508, 'learning_rate': 9.82764563943468e-06, 'epoch': 0.3447087211306446}\n",
            "{'loss': 2.4985, 'grad_norm': 28.57296371459961, 'learning_rate': 9.741468459152018e-06, 'epoch': 0.5170630816959669}\n",
            "{'loss': 2.4697, 'grad_norm': 14.74521255493164, 'learning_rate': 9.655291278869356e-06, 'epoch': 0.6894174422612892}\n",
            "{'loss': 2.3647, 'grad_norm': 39.008914947509766, 'learning_rate': 9.569114098586695e-06, 'epoch': 0.8617718028266115}\n",
            "{'eval_loss': 2.4494917392730713, 'eval_runtime': 1.8331, 'eval_samples_per_second': 350.765, 'eval_steps_per_second': 350.765, 'epoch': 1.0}\n",
            "{'loss': 2.1876, 'grad_norm': 45.49576187133789, 'learning_rate': 9.482936918304035e-06, 'epoch': 1.0341261633919339}\n",
            "{'loss': 2.0517, 'grad_norm': 72.8843002319336, 'learning_rate': 9.396759738021373e-06, 'epoch': 1.206480523957256}\n",
            "{'loss': 2.1568, 'grad_norm': 43.04755401611328, 'learning_rate': 9.310582557738711e-06, 'epoch': 1.3788348845225784}\n",
            "{'loss': 2.0686, 'grad_norm': 25.70734214782715, 'learning_rate': 9.22440537745605e-06, 'epoch': 1.5511892450879006}\n",
            "{'loss': 1.9956, 'grad_norm': 76.59703063964844, 'learning_rate': 9.138228197173388e-06, 'epoch': 1.723543605653223}\n",
            "{'loss': 1.9588, 'grad_norm': 20.36141014099121, 'learning_rate': 9.052051016890728e-06, 'epoch': 1.8958979662185453}\n",
            "{'eval_loss': 2.3089828491210938, 'eval_runtime': 1.8358, 'eval_samples_per_second': 350.263, 'eval_steps_per_second': 350.263, 'epoch': 2.0}\n",
            "{'loss': 1.8679, 'grad_norm': 220.66616821289062, 'learning_rate': 8.965873836608067e-06, 'epoch': 2.0682523267838677}\n",
            "{'loss': 1.6508, 'grad_norm': 130.03631591796875, 'learning_rate': 8.879696656325407e-06, 'epoch': 2.24060668734919}\n",
            "{'loss': 1.7284, 'grad_norm': 40.36338424682617, 'learning_rate': 8.793519476042745e-06, 'epoch': 2.412961047914512}\n",
            "{'loss': 1.8041, 'grad_norm': 104.60160064697266, 'learning_rate': 8.707342295760084e-06, 'epoch': 2.5853154084798344}\n",
            "{'loss': 1.8813, 'grad_norm': 84.56153106689453, 'learning_rate': 8.621165115477422e-06, 'epoch': 2.757669769045157}\n",
            "{'loss': 1.6041, 'grad_norm': 11.512929916381836, 'learning_rate': 8.53498793519476e-06, 'epoch': 2.930024129610479}\n",
            "{'eval_loss': 2.6543238162994385, 'eval_runtime': 1.9548, 'eval_samples_per_second': 328.94, 'eval_steps_per_second': 328.94, 'epoch': 3.0}\n",
            "{'loss': 1.4349, 'grad_norm': 5.310657978057861, 'learning_rate': 8.4488107549121e-06, 'epoch': 3.1023784901758016}\n",
            "{'loss': 1.484, 'grad_norm': 0.003339339978992939, 'learning_rate': 8.362633574629439e-06, 'epoch': 3.274732850741124}\n",
            "{'loss': 1.4929, 'grad_norm': 42.05403518676758, 'learning_rate': 8.276456394346777e-06, 'epoch': 3.447087211306446}\n",
            "{'loss': 1.4512, 'grad_norm': 0.024158215150237083, 'learning_rate': 8.190279214064116e-06, 'epoch': 3.6194415718717683}\n",
            "{'loss': 1.5186, 'grad_norm': 296.5398254394531, 'learning_rate': 8.104102033781456e-06, 'epoch': 3.7917959324370907}\n",
            "{'loss': 1.4463, 'grad_norm': 51.580787658691406, 'learning_rate': 8.017924853498794e-06, 'epoch': 3.964150293002413}\n",
            "{'eval_loss': 2.6055705547332764, 'eval_runtime': 1.9389, 'eval_samples_per_second': 331.637, 'eval_steps_per_second': 331.637, 'epoch': 4.0}\n",
            "{'loss': 1.2683, 'grad_norm': 3.1434452533721924, 'learning_rate': 7.931747673216133e-06, 'epoch': 4.1365046535677354}\n",
            "{'loss': 1.1566, 'grad_norm': 0.007663877215236425, 'learning_rate': 7.845570492933473e-06, 'epoch': 4.308859014133057}\n",
            "{'loss': 1.1804, 'grad_norm': 2.425457000732422, 'learning_rate': 7.759393312650811e-06, 'epoch': 4.48121337469838}\n",
            "{'loss': 1.3661, 'grad_norm': 0.01048340369015932, 'learning_rate': 7.67321613236815e-06, 'epoch': 4.653567735263702}\n",
            "{'loss': 1.4027, 'grad_norm': 28.231266021728516, 'learning_rate': 7.587038952085488e-06, 'epoch': 4.825922095829024}\n",
            "{'loss': 1.147, 'grad_norm': 273.888916015625, 'learning_rate': 7.500861771802828e-06, 'epoch': 4.998276456394347}\n",
            "{'eval_loss': 3.4748637676239014, 'eval_runtime': 1.9662, 'eval_samples_per_second': 327.03, 'eval_steps_per_second': 327.03, 'epoch': 5.0}\n",
            "{'loss': 1.0561, 'grad_norm': 0.02591642551124096, 'learning_rate': 7.414684591520166e-06, 'epoch': 5.170630816959669}\n",
            "{'loss': 0.9734, 'grad_norm': 59.944129943847656, 'learning_rate': 7.328507411237506e-06, 'epoch': 5.342985177524992}\n",
            "{'loss': 1.2047, 'grad_norm': 0.0010679332772269845, 'learning_rate': 7.242330230954844e-06, 'epoch': 5.515339538090314}\n",
            "{'loss': 1.001, 'grad_norm': 11.426092147827148, 'learning_rate': 7.156153050672182e-06, 'epoch': 5.6876938986556365}\n",
            "{'loss': 1.1374, 'grad_norm': 0.01487013790756464, 'learning_rate': 7.069975870389522e-06, 'epoch': 5.860048259220958}\n",
            "{'eval_loss': 3.343350648880005, 'eval_runtime': 1.9549, 'eval_samples_per_second': 328.918, 'eval_steps_per_second': 328.918, 'epoch': 6.0}\n",
            "{'loss': 1.039, 'grad_norm': 1.9399878978729248, 'learning_rate': 6.98379869010686e-06, 'epoch': 6.03240261978628}\n",
            "{'loss': 0.8585, 'grad_norm': 0.0006045504123903811, 'learning_rate': 6.897621509824199e-06, 'epoch': 6.204756980351603}\n",
            "{'loss': 0.8545, 'grad_norm': 0.0008923143032006919, 'learning_rate': 6.811444329541538e-06, 'epoch': 6.377111340916925}\n",
            "{'loss': 1.0388, 'grad_norm': 84.81047821044922, 'learning_rate': 6.725267149258877e-06, 'epoch': 6.549465701482248}\n",
            "{'loss': 0.8869, 'grad_norm': 0.5839723944664001, 'learning_rate': 6.639089968976215e-06, 'epoch': 6.72182006204757}\n",
            "{'loss': 1.085, 'grad_norm': 3.14683198928833, 'learning_rate': 6.552912788693554e-06, 'epoch': 6.894174422612892}\n",
            "{'eval_loss': 3.7611629962921143, 'eval_runtime': 1.826, 'eval_samples_per_second': 352.129, 'eval_steps_per_second': 352.129, 'epoch': 7.0}\n",
            "{'loss': 0.8742, 'grad_norm': 9.188624382019043, 'learning_rate': 6.466735608410894e-06, 'epoch': 7.066528783178215}\n",
            "{'loss': 0.7921, 'grad_norm': 301.3366394042969, 'learning_rate': 6.380558428128231e-06, 'epoch': 7.238883143743537}\n",
            "{'loss': 0.715, 'grad_norm': 123.58535766601562, 'learning_rate': 6.2943812478455715e-06, 'epoch': 7.411237504308859}\n",
            "{'loss': 0.7394, 'grad_norm': 0.002550683217123151, 'learning_rate': 6.20820406756291e-06, 'epoch': 7.583591864874181}\n",
            "{'loss': 0.7789, 'grad_norm': 284.8499755859375, 'learning_rate': 6.122026887280249e-06, 'epoch': 7.755946225439503}\n",
            "{'loss': 0.8723, 'grad_norm': 0.6139338612556458, 'learning_rate': 6.0358497069975875e-06, 'epoch': 7.928300586004826}\n",
            "{'eval_loss': 4.497459888458252, 'eval_runtime': 1.8286, 'eval_samples_per_second': 351.64, 'eval_steps_per_second': 351.64, 'epoch': 8.0}\n",
            "{'loss': 0.6688, 'grad_norm': 4.42508602142334, 'learning_rate': 5.949672526714927e-06, 'epoch': 8.100654946570149}\n",
            "{'loss': 0.5579, 'grad_norm': 0.0002966856409329921, 'learning_rate': 5.863495346432265e-06, 'epoch': 8.273009307135471}\n",
            "{'loss': 0.7463, 'grad_norm': 0.0005963909788988531, 'learning_rate': 5.7773181661496036e-06, 'epoch': 8.445363667700793}\n",
            "{'loss': 0.7201, 'grad_norm': 0.01244005374610424, 'learning_rate': 5.691140985866943e-06, 'epoch': 8.617718028266115}\n",
            "{'loss': 0.7283, 'grad_norm': 133.42935180664062, 'learning_rate': 5.604963805584281e-06, 'epoch': 8.790072388831437}\n",
            "{'loss': 0.6783, 'grad_norm': 0.016079969704151154, 'learning_rate': 5.518786625301621e-06, 'epoch': 8.96242674939676}\n",
            "{'eval_loss': 4.6486406326293945, 'eval_runtime': 1.8456, 'eval_samples_per_second': 348.397, 'eval_steps_per_second': 348.397, 'epoch': 9.0}\n",
            "{'loss': 0.5989, 'grad_norm': 95.33231353759766, 'learning_rate': 5.432609445018959e-06, 'epoch': 9.134781109962082}\n",
            "{'loss': 0.5787, 'grad_norm': 63.109230041503906, 'learning_rate': 5.346432264736299e-06, 'epoch': 9.307135470527404}\n",
            "{'loss': 0.5652, 'grad_norm': 268.32904052734375, 'learning_rate': 5.260255084453637e-06, 'epoch': 9.479489831092726}\n",
            "{'loss': 0.5345, 'grad_norm': 2.2589590549468994, 'learning_rate': 5.174077904170976e-06, 'epoch': 9.651844191658048}\n",
            "{'loss': 0.5293, 'grad_norm': 177.24119567871094, 'learning_rate': 5.087900723888315e-06, 'epoch': 9.824198552223372}\n",
            "{'loss': 0.7061, 'grad_norm': 202.86074829101562, 'learning_rate': 5.001723543605653e-06, 'epoch': 9.996552912788694}\n",
            "{'eval_loss': 5.006229400634766, 'eval_runtime': 1.8407, 'eval_samples_per_second': 349.33, 'eval_steps_per_second': 349.33, 'epoch': 10.0}\n",
            "{'loss': 0.4171, 'grad_norm': 9.993919229600579e-05, 'learning_rate': 4.915546363322993e-06, 'epoch': 10.168907273354016}\n",
            "{'loss': 0.5413, 'grad_norm': 155.1760711669922, 'learning_rate': 4.829369183040331e-06, 'epoch': 10.341261633919338}\n",
            "{'loss': 0.5304, 'grad_norm': 0.05777488276362419, 'learning_rate': 4.74319200275767e-06, 'epoch': 10.51361599448466}\n",
            "{'loss': 0.5487, 'grad_norm': 0.7067098021507263, 'learning_rate': 4.657014822475009e-06, 'epoch': 10.685970355049983}\n",
            "{'loss': 0.4792, 'grad_norm': 0.0059503596276044846, 'learning_rate': 4.570837642192348e-06, 'epoch': 10.858324715615305}\n",
            "{'eval_loss': 5.9852681159973145, 'eval_runtime': 1.8393, 'eval_samples_per_second': 349.591, 'eval_steps_per_second': 349.591, 'epoch': 11.0}\n",
            "{'loss': 0.5684, 'grad_norm': 0.18602806329727173, 'learning_rate': 4.484660461909686e-06, 'epoch': 11.030679076180627}\n",
            "{'loss': 0.4238, 'grad_norm': 6.99847805663012e-05, 'learning_rate': 4.398483281627026e-06, 'epoch': 11.20303343674595}\n",
            "{'loss': 0.415, 'grad_norm': 0.01611986756324768, 'learning_rate': 4.312306101344365e-06, 'epoch': 11.375387797311271}\n",
            "{'loss': 0.4434, 'grad_norm': 305.82269287109375, 'learning_rate': 4.226128921061703e-06, 'epoch': 11.547742157876595}\n",
            "{'loss': 0.4407, 'grad_norm': 0.0004715998366009444, 'learning_rate': 4.139951740779042e-06, 'epoch': 11.720096518441917}\n",
            "{'loss': 0.535, 'grad_norm': 0.0005348573322407901, 'learning_rate': 4.053774560496381e-06, 'epoch': 11.892450879007239}\n",
            "{'eval_loss': 5.892698764801025, 'eval_runtime': 1.8394, 'eval_samples_per_second': 349.568, 'eval_steps_per_second': 349.568, 'epoch': 12.0}\n",
            "{'loss': 0.4578, 'grad_norm': 0.02823483943939209, 'learning_rate': 3.967597380213719e-06, 'epoch': 12.06480523957256}\n",
            "{'loss': 0.2872, 'grad_norm': 174.64749145507812, 'learning_rate': 3.8814201999310585e-06, 'epoch': 12.237159600137883}\n",
            "{'loss': 0.4037, 'grad_norm': 0.11321386694908142, 'learning_rate': 3.7952430196483974e-06, 'epoch': 12.409513960703206}\n",
            "{'loss': 0.3751, 'grad_norm': 261.9891052246094, 'learning_rate': 3.7090658393657366e-06, 'epoch': 12.581868321268528}\n",
            "{'loss': 0.4671, 'grad_norm': 0.8816535472869873, 'learning_rate': 3.6228886590830754e-06, 'epoch': 12.75422268183385}\n",
            "{'loss': 0.4338, 'grad_norm': 25.904739379882812, 'learning_rate': 3.5367114788004142e-06, 'epoch': 12.926577042399172}\n",
            "{'eval_loss': 6.21607780456543, 'eval_runtime': 1.8408, 'eval_samples_per_second': 349.298, 'eval_steps_per_second': 349.298, 'epoch': 13.0}\n",
            "{'loss': 0.3655, 'grad_norm': 0.060739435255527496, 'learning_rate': 3.4505342985177526e-06, 'epoch': 13.098931402964496}\n",
            "{'loss': 0.3272, 'grad_norm': 3.276234201621264e-05, 'learning_rate': 3.3643571182350915e-06, 'epoch': 13.271285763529818}\n",
            "{'loss': 0.3172, 'grad_norm': 0.008053308352828026, 'learning_rate': 3.2781799379524303e-06, 'epoch': 13.44364012409514}\n",
            "{'loss': 0.3071, 'grad_norm': 0.7212425470352173, 'learning_rate': 3.192002757669769e-06, 'epoch': 13.615994484660462}\n",
            "{'loss': 0.3242, 'grad_norm': 209.25437927246094, 'learning_rate': 3.1058255773871084e-06, 'epoch': 13.788348845225784}\n",
            "{'loss': 0.2909, 'grad_norm': 0.0011628989595919847, 'learning_rate': 3.019648397104447e-06, 'epoch': 13.960703205791106}\n",
            "{'eval_loss': 6.54996395111084, 'eval_runtime': 1.9498, 'eval_samples_per_second': 329.777, 'eval_steps_per_second': 329.777, 'epoch': 14.0}\n",
            "{'loss': 0.1922, 'grad_norm': 6.755667527613696e-06, 'learning_rate': 2.933471216821786e-06, 'epoch': 14.13305756635643}\n",
            "{'loss': 0.1743, 'grad_norm': 8.240147590637207, 'learning_rate': 2.8472940365391244e-06, 'epoch': 14.305411926921751}\n",
            "{'loss': 0.3078, 'grad_norm': 0.009325848892331123, 'learning_rate': 2.7611168562564632e-06, 'epoch': 14.477766287487073}\n",
            "{'loss': 0.2103, 'grad_norm': 11.169705390930176, 'learning_rate': 2.674939675973802e-06, 'epoch': 14.650120648052395}\n",
            "{'loss': 0.3115, 'grad_norm': 0.0005561391590163112, 'learning_rate': 2.5887624956911413e-06, 'epoch': 14.822475008617719}\n",
            "{'loss': 0.3257, 'grad_norm': 0.0040414887480437756, 'learning_rate': 2.50258531540848e-06, 'epoch': 14.99482936918304}\n",
            "{'eval_loss': 6.924783229827881, 'eval_runtime': 1.9402, 'eval_samples_per_second': 331.405, 'eval_steps_per_second': 331.405, 'epoch': 15.0}\n",
            "{'loss': 0.2836, 'grad_norm': 3.819138146354817e-05, 'learning_rate': 2.416408135125819e-06, 'epoch': 15.167183729748363}\n",
            "{'loss': 0.2748, 'grad_norm': 0.0011703615309670568, 'learning_rate': 2.3302309548431578e-06, 'epoch': 15.339538090313685}\n",
            "{'loss': 0.173, 'grad_norm': 1389.854248046875, 'learning_rate': 2.2440537745604966e-06, 'epoch': 15.511892450879007}\n",
            "{'loss': 0.2488, 'grad_norm': 0.023083791136741638, 'learning_rate': 2.1578765942778354e-06, 'epoch': 15.68424681144433}\n",
            "{'loss': 0.2118, 'grad_norm': 2.340185528737493e-05, 'learning_rate': 2.0716994139951742e-06, 'epoch': 15.856601172009652}\n",
            "{'eval_loss': 6.36279821395874, 'eval_runtime': 1.8952, 'eval_samples_per_second': 339.279, 'eval_steps_per_second': 339.279, 'epoch': 16.0}\n",
            "{'loss': 0.1886, 'grad_norm': 0.006989342160522938, 'learning_rate': 1.985522233712513e-06, 'epoch': 16.028955532574972}\n",
            "{'loss': 0.1943, 'grad_norm': 0.03155137971043587, 'learning_rate': 1.8993450534298519e-06, 'epoch': 16.201309893140298}\n",
            "{'loss': 0.2453, 'grad_norm': 2.036830892393482e-06, 'learning_rate': 1.8131678731471907e-06, 'epoch': 16.37366425370562}\n",
            "{'loss': 0.1799, 'grad_norm': 0.003191831521689892, 'learning_rate': 1.7269906928645297e-06, 'epoch': 16.546018614270942}\n",
            "{'loss': 0.2891, 'grad_norm': 53.794593811035156, 'learning_rate': 1.6408135125818684e-06, 'epoch': 16.718372974836264}\n",
            "{'loss': 0.1576, 'grad_norm': 4.073843683727318e-06, 'learning_rate': 1.5546363322992072e-06, 'epoch': 16.890727335401586}\n",
            "{'eval_loss': 7.049717903137207, 'eval_runtime': 1.9103, 'eval_samples_per_second': 336.591, 'eval_steps_per_second': 336.591, 'epoch': 17.0}\n",
            "{'loss': 0.19, 'grad_norm': 0.0001922689552884549, 'learning_rate': 1.4684591520165462e-06, 'epoch': 17.063081695966908}\n",
            "{'loss': 0.1045, 'grad_norm': 5.1035560318268836e-05, 'learning_rate': 1.382281971733885e-06, 'epoch': 17.23543605653223}\n",
            "{'loss': 0.1978, 'grad_norm': 1.0147205591201782, 'learning_rate': 1.2961047914512236e-06, 'epoch': 17.40779041709755}\n",
            "{'loss': 0.1325, 'grad_norm': 0.00038146396400406957, 'learning_rate': 1.2099276111685627e-06, 'epoch': 17.580144777662873}\n",
            "{'loss': 0.2158, 'grad_norm': 11.49411678314209, 'learning_rate': 1.1237504308859015e-06, 'epoch': 17.752499138228195}\n",
            "{'loss': 0.1158, 'grad_norm': 0.04602932184934616, 'learning_rate': 1.0375732506032403e-06, 'epoch': 17.92485349879352}\n",
            "{'eval_loss': 6.979912281036377, 'eval_runtime': 1.9164, 'eval_samples_per_second': 335.526, 'eval_steps_per_second': 335.526, 'epoch': 18.0}\n",
            "{'loss': 0.2139, 'grad_norm': 0.7190310955047607, 'learning_rate': 9.513960703205793e-07, 'epoch': 18.097207859358843}\n",
            "{'loss': 0.1038, 'grad_norm': 0.016445131972432137, 'learning_rate': 8.65218890037918e-07, 'epoch': 18.269562219924165}\n",
            "{'loss': 0.1127, 'grad_norm': 0.00034832494566217065, 'learning_rate': 7.790417097552569e-07, 'epoch': 18.441916580489487}\n",
            "{'loss': 0.1584, 'grad_norm': 0.016622411087155342, 'learning_rate': 6.928645294725956e-07, 'epoch': 18.61427094105481}\n",
            "{'loss': 0.241, 'grad_norm': 4.992212295532227, 'learning_rate': 6.066873491899345e-07, 'epoch': 18.78662530162013}\n",
            "{'loss': 0.1472, 'grad_norm': 8.692764282226562, 'learning_rate': 5.205101689072734e-07, 'epoch': 18.958979662185452}\n",
            "{'eval_loss': 6.99039363861084, 'eval_runtime': 1.9131, 'eval_samples_per_second': 336.096, 'eval_steps_per_second': 336.096, 'epoch': 19.0}\n",
            "{'loss': 0.1363, 'grad_norm': 0.0034590596333146095, 'learning_rate': 4.3433298862461224e-07, 'epoch': 19.131334022750774}\n",
            "{'loss': 0.1163, 'grad_norm': 0.04270729050040245, 'learning_rate': 3.481558083419511e-07, 'epoch': 19.303688383316096}\n",
            "{'loss': 0.1673, 'grad_norm': 0.0024852347560226917, 'learning_rate': 2.619786280592899e-07, 'epoch': 19.476042743881422}\n",
            "{'loss': 0.0809, 'grad_norm': 10.448180198669434, 'learning_rate': 1.7580144777662877e-07, 'epoch': 19.648397104446744}\n",
            "{'loss': 0.1158, 'grad_norm': 1139.514892578125, 'learning_rate': 8.96242674939676e-08, 'epoch': 19.820751465012066}\n",
            "{'loss': 0.0879, 'grad_norm': 0.007748931646347046, 'learning_rate': 3.4470872113064463e-09, 'epoch': 19.993105825577388}\n",
            "{'eval_loss': 7.200887203216553, 'eval_runtime': 1.9178, 'eval_samples_per_second': 335.273, 'eval_steps_per_second': 335.273, 'epoch': 20.0}\n",
            "{'train_runtime': 1662.4687, 'train_samples_per_second': 34.9, 'train_steps_per_second': 34.9, 'train_loss': 0.7974783359376039, 'epoch': 20.0}\n",
            "model m-distil-bert train time 0:27:42.582965\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 643/643 [00:01<00:00, 470.25it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "model m-distil-bert invalid f1 score 1.1547110731568462\n",
            "model m-distil-bert squad results {'exact': 17.418351477449455, 'f1': 49.03699913975556, 'total': 643, 'HasAns_exact': 17.418351477449455, 'HasAns_f1': 49.03699913975556, 'HasAns_total': 643, 'best_exact': 17.418351477449455, 'best_exact_thresh': 0.0, 'best_f1': 49.03699913975556, 'best_f1_thresh': 0.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Map: 100%|██████████| 2901/2901 [00:00<00:00, 8468.93 examples/s]\n",
            "Map: 100%|██████████| 643/643 [00:00<00:00, 7453.11 examples/s]\n",
            "/home/orian/PycharmProjects/ANLP/venv/lib/python3.10/site-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 3.8805, 'grad_norm': 74.78357696533203, 'learning_rate': 2.9482936918304035e-05, 'epoch': 0.1723543605653223}\n",
            "{'loss': 5.6491, 'grad_norm': 21.871646881103516, 'learning_rate': 2.896587383660807e-05, 'epoch': 0.3447087211306446}\n",
            "{'loss': 6.0231, 'grad_norm': 19.236549377441406, 'learning_rate': 2.8448810754912102e-05, 'epoch': 0.5170630816959669}\n",
            "{'loss': 4.6784, 'grad_norm': 21.386695861816406, 'learning_rate': 2.7931747673216133e-05, 'epoch': 0.6894174422612892}\n",
            "{'loss': 2.875, 'grad_norm': 22.409034729003906, 'learning_rate': 2.7414684591520166e-05, 'epoch': 0.8617718028266115}\n",
            "{'eval_loss': 2.7091434001922607, 'eval_runtime': 3.5377, 'eval_samples_per_second': 181.756, 'eval_steps_per_second': 181.756, 'epoch': 1.0}\n",
            "{'loss': 2.7743, 'grad_norm': 38.38597869873047, 'learning_rate': 2.68976215098242e-05, 'epoch': 1.0341261633919339}\n",
            "{'loss': 2.7103, 'grad_norm': 28.12925148010254, 'learning_rate': 2.638055842812823e-05, 'epoch': 1.206480523957256}\n",
            "{'loss': 2.7023, 'grad_norm': 14.246933937072754, 'learning_rate': 2.5863495346432264e-05, 'epoch': 1.3788348845225784}\n",
            "{'loss': 2.5169, 'grad_norm': 40.68013381958008, 'learning_rate': 2.5346432264736298e-05, 'epoch': 1.5511892450879006}\n",
            "{'loss': 2.4951, 'grad_norm': 65.45021057128906, 'learning_rate': 2.4829369183040332e-05, 'epoch': 1.723543605653223}\n",
            "{'loss': 2.3027, 'grad_norm': 18.348644256591797, 'learning_rate': 2.4312306101344366e-05, 'epoch': 1.8958979662185453}\n",
            "{'eval_loss': 2.455298900604248, 'eval_runtime': 3.4809, 'eval_samples_per_second': 184.722, 'eval_steps_per_second': 184.722, 'epoch': 2.0}\n",
            "{'loss': 2.2674, 'grad_norm': 68.14591979980469, 'learning_rate': 2.3795243019648396e-05, 'epoch': 2.0682523267838677}\n",
            "{'loss': 2.2096, 'grad_norm': 47.778873443603516, 'learning_rate': 2.327817993795243e-05, 'epoch': 2.24060668734919}\n",
            "{'loss': 2.2087, 'grad_norm': 71.23858642578125, 'learning_rate': 2.2761116856256464e-05, 'epoch': 2.412961047914512}\n",
            "{'loss': 2.2336, 'grad_norm': 218.86459350585938, 'learning_rate': 2.2244053774560497e-05, 'epoch': 2.5853154084798344}\n",
            "{'loss': 2.2745, 'grad_norm': 38.4531135559082, 'learning_rate': 2.172699069286453e-05, 'epoch': 2.757669769045157}\n",
            "{'loss': 2.0118, 'grad_norm': 118.2003402709961, 'learning_rate': 2.1209927611168565e-05, 'epoch': 2.930024129610479}\n",
            "{'eval_loss': 2.567505359649658, 'eval_runtime': 3.5484, 'eval_samples_per_second': 181.21, 'eval_steps_per_second': 181.21, 'epoch': 3.0}\n",
            "{'loss': 1.9807, 'grad_norm': 74.0645523071289, 'learning_rate': 2.06928645294726e-05, 'epoch': 3.1023784901758016}\n",
            "{'loss': 1.9325, 'grad_norm': 0.09324654191732407, 'learning_rate': 2.017580144777663e-05, 'epoch': 3.274732850741124}\n",
            "{'loss': 2.0311, 'grad_norm': 55.15230178833008, 'learning_rate': 1.965873836608066e-05, 'epoch': 3.447087211306446}\n",
            "{'loss': 1.7831, 'grad_norm': 0.010557850822806358, 'learning_rate': 1.9141675284384693e-05, 'epoch': 3.6194415718717683}\n",
            "{'loss': 1.9752, 'grad_norm': 191.88897705078125, 'learning_rate': 1.8624612202688727e-05, 'epoch': 3.7917959324370907}\n",
            "{'loss': 1.8165, 'grad_norm': 138.50653076171875, 'learning_rate': 1.810754912099276e-05, 'epoch': 3.964150293002413}\n",
            "{'eval_loss': 2.2539803981781006, 'eval_runtime': 3.4552, 'eval_samples_per_second': 186.097, 'eval_steps_per_second': 186.097, 'epoch': 4.0}\n",
            "{'loss': 1.7013, 'grad_norm': 36.961612701416016, 'learning_rate': 1.7590486039296795e-05, 'epoch': 4.1365046535677354}\n",
            "{'loss': 1.6135, 'grad_norm': 0.1939728707075119, 'learning_rate': 1.707342295760083e-05, 'epoch': 4.308859014133057}\n",
            "{'loss': 1.6051, 'grad_norm': 24.363990783691406, 'learning_rate': 1.6556359875904862e-05, 'epoch': 4.48121337469838}\n",
            "{'loss': 1.7686, 'grad_norm': 0.3209960460662842, 'learning_rate': 1.6039296794208896e-05, 'epoch': 4.653567735263702}\n",
            "{'loss': 1.7557, 'grad_norm': 7.707970142364502, 'learning_rate': 1.5522233712512926e-05, 'epoch': 4.825922095829024}\n",
            "{'loss': 1.529, 'grad_norm': 114.31059265136719, 'learning_rate': 1.5005170630816959e-05, 'epoch': 4.998276456394347}\n",
            "{'eval_loss': 3.133411169052124, 'eval_runtime': 3.5074, 'eval_samples_per_second': 183.326, 'eval_steps_per_second': 183.326, 'epoch': 5.0}\n",
            "{'loss': 1.3931, 'grad_norm': 29.110231399536133, 'learning_rate': 1.4488107549120992e-05, 'epoch': 5.170630816959669}\n",
            "{'loss': 1.3312, 'grad_norm': 0.4378718435764313, 'learning_rate': 1.3971044467425026e-05, 'epoch': 5.342985177524992}\n",
            "{'loss': 1.6082, 'grad_norm': 0.04087161272764206, 'learning_rate': 1.345398138572906e-05, 'epoch': 5.515339538090314}\n",
            "{'loss': 1.3156, 'grad_norm': 91.57141876220703, 'learning_rate': 1.2936918304033094e-05, 'epoch': 5.6876938986556365}\n",
            "{'loss': 1.4948, 'grad_norm': 0.001531021436676383, 'learning_rate': 1.2419855222337124e-05, 'epoch': 5.860048259220958}\n",
            "{'eval_loss': 3.3732967376708984, 'eval_runtime': 3.4856, 'eval_samples_per_second': 184.474, 'eval_steps_per_second': 184.474, 'epoch': 6.0}\n",
            "{'loss': 1.2935, 'grad_norm': 0.00924909021705389, 'learning_rate': 1.1902792140641158e-05, 'epoch': 6.03240261978628}\n",
            "{'loss': 1.071, 'grad_norm': 0.0013967107515782118, 'learning_rate': 1.1385729058945192e-05, 'epoch': 6.204756980351603}\n",
            "{'loss': 1.041, 'grad_norm': 0.002646885346621275, 'learning_rate': 1.0868665977249225e-05, 'epoch': 6.377111340916925}\n",
            "{'loss': 1.173, 'grad_norm': 250.14752197265625, 'learning_rate': 1.0351602895553258e-05, 'epoch': 6.549465701482248}\n",
            "{'loss': 1.2096, 'grad_norm': 0.3864911198616028, 'learning_rate': 9.834539813857291e-06, 'epoch': 6.72182006204757}\n",
            "{'loss': 1.1674, 'grad_norm': 38.45561218261719, 'learning_rate': 9.317476732161323e-06, 'epoch': 6.894174422612892}\n",
            "{'eval_loss': 3.9894628524780273, 'eval_runtime': 3.5681, 'eval_samples_per_second': 180.207, 'eval_steps_per_second': 180.207, 'epoch': 7.0}\n",
            "{'loss': 0.9402, 'grad_norm': 0.6337594389915466, 'learning_rate': 8.800413650465357e-06, 'epoch': 7.066528783178215}\n",
            "{'loss': 0.817, 'grad_norm': 11.452025413513184, 'learning_rate': 8.28335056876939e-06, 'epoch': 7.238883143743537}\n",
            "{'loss': 0.8703, 'grad_norm': 1.9529757499694824, 'learning_rate': 7.766287487073423e-06, 'epoch': 7.411237504308859}\n",
            "{'loss': 0.944, 'grad_norm': 0.0012613792205229402, 'learning_rate': 7.249224405377457e-06, 'epoch': 7.583591864874181}\n",
            "{'loss': 0.9974, 'grad_norm': 814.6018676757812, 'learning_rate': 6.732161323681489e-06, 'epoch': 7.755946225439503}\n",
            "{'loss': 1.0286, 'grad_norm': 0.004811727441847324, 'learning_rate': 6.215098241985523e-06, 'epoch': 7.928300586004826}\n",
            "{'eval_loss': 4.175357341766357, 'eval_runtime': 3.5592, 'eval_samples_per_second': 180.658, 'eval_steps_per_second': 180.658, 'epoch': 8.0}\n",
            "{'loss': 0.7619, 'grad_norm': 0.000989121850579977, 'learning_rate': 5.698035160289556e-06, 'epoch': 8.100654946570149}\n",
            "{'loss': 0.6458, 'grad_norm': 0.0034974608570337296, 'learning_rate': 5.180972078593589e-06, 'epoch': 8.273009307135471}\n",
            "{'loss': 0.7068, 'grad_norm': 0.007196966093033552, 'learning_rate': 4.6639089968976215e-06, 'epoch': 8.445363667700793}\n",
            "{'loss': 0.7369, 'grad_norm': 0.0001861490891315043, 'learning_rate': 4.146845915201655e-06, 'epoch': 8.617718028266115}\n",
            "{'loss': 0.8035, 'grad_norm': 147.5605010986328, 'learning_rate': 3.629782833505688e-06, 'epoch': 8.790072388831437}\n",
            "{'loss': 0.7248, 'grad_norm': 0.038820259273052216, 'learning_rate': 3.1127197518097208e-06, 'epoch': 8.96242674939676}\n",
            "{'eval_loss': 4.538972854614258, 'eval_runtime': 3.4574, 'eval_samples_per_second': 185.979, 'eval_steps_per_second': 185.979, 'epoch': 9.0}\n",
            "{'loss': 0.684, 'grad_norm': 67.56391906738281, 'learning_rate': 2.5956566701137537e-06, 'epoch': 9.134781109962082}\n",
            "{'loss': 0.5024, 'grad_norm': 242.98489379882812, 'learning_rate': 2.078593588417787e-06, 'epoch': 9.307135470527404}\n",
            "{'loss': 0.5197, 'grad_norm': 684.5232543945312, 'learning_rate': 1.5615305067218202e-06, 'epoch': 9.479489831092726}\n",
            "{'loss': 0.5472, 'grad_norm': 0.16074855625629425, 'learning_rate': 1.0444674250258532e-06, 'epoch': 9.651844191658048}\n",
            "{'loss': 0.5684, 'grad_norm': 282.9900207519531, 'learning_rate': 5.274043433298862e-07, 'epoch': 9.824198552223372}\n",
            "{'loss': 0.6867, 'grad_norm': 18.030424118041992, 'learning_rate': 1.0341261633919339e-08, 'epoch': 9.996552912788694}\n",
            "{'eval_loss': 5.236847400665283, 'eval_runtime': 3.4807, 'eval_samples_per_second': 184.733, 'eval_steps_per_second': 184.733, 'epoch': 10.0}\n",
            "{'train_runtime': 1657.0528, 'train_samples_per_second': 17.507, 'train_steps_per_second': 17.507, 'train_loss': 1.7390518687010552, 'epoch': 10.0}\n",
            "model xlm-roberta train time 0:27:37.153507\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 643/643 [00:01<00:00, 331.94it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "model xlm-roberta invalid f1 score 1.0327361563517916\n",
            "model xlm-roberta squad results {'exact': 23.17262830482115, 'f1': 47.158801493964475, 'total': 643, 'HasAns_exact': 23.17262830482115, 'HasAns_f1': 47.158801493964475, 'HasAns_total': 643, 'best_exact': 23.17262830482115, 'best_exact_thresh': 0.0, 'best_f1': 47.158801493964475, 'best_f1_thresh': 0.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Map: 100%|██████████| 2901/2901 [00:00<00:00, 7864.14 examples/s]\n",
            "Map: 100%|██████████| 643/643 [00:00<00:00, 7985.65 examples/s]\n",
            "/home/orian/PycharmProjects/ANLP/venv/lib/python3.10/site-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 3.0836, 'grad_norm': 42.9755859375, 'learning_rate': 4.913822819717339e-05, 'epoch': 0.1723543605653223}\n",
            "{'loss': 2.758, 'grad_norm': 11.617218971252441, 'learning_rate': 4.8276456394346784e-05, 'epoch': 0.3447087211306446}\n",
            "{'loss': 2.4953, 'grad_norm': 53.5815315246582, 'learning_rate': 4.741468459152017e-05, 'epoch': 0.5170630816959669}\n",
            "{'loss': 2.5723, 'grad_norm': 28.144235610961914, 'learning_rate': 4.655291278869355e-05, 'epoch': 0.6894174422612892}\n",
            "{'loss': 2.3737, 'grad_norm': 97.50458526611328, 'learning_rate': 4.569114098586694e-05, 'epoch': 0.8617718028266115}\n",
            "{'eval_loss': 2.6628711223602295, 'eval_runtime': 3.4697, 'eval_samples_per_second': 185.319, 'eval_steps_per_second': 185.319, 'epoch': 1.0}\n",
            "{'loss': 2.2301, 'grad_norm': 102.36447143554688, 'learning_rate': 4.4829369183040333e-05, 'epoch': 1.0341261633919339}\n",
            "{'loss': 2.0602, 'grad_norm': 58.31784439086914, 'learning_rate': 4.3967597380213724e-05, 'epoch': 1.206480523957256}\n",
            "{'loss': 2.0639, 'grad_norm': 33.797203063964844, 'learning_rate': 4.310582557738711e-05, 'epoch': 1.3788348845225784}\n",
            "{'loss': 2.0315, 'grad_norm': 26.15491485595703, 'learning_rate': 4.22440537745605e-05, 'epoch': 1.5511892450879006}\n",
            "{'loss': 2.0021, 'grad_norm': 71.20208740234375, 'learning_rate': 4.138228197173389e-05, 'epoch': 1.723543605653223}\n",
            "{'loss': 2.0584, 'grad_norm': 7.772243022918701, 'learning_rate': 4.052051016890728e-05, 'epoch': 1.8958979662185453}\n",
            "{'eval_loss': 2.353695869445801, 'eval_runtime': 3.4452, 'eval_samples_per_second': 186.635, 'eval_steps_per_second': 186.635, 'epoch': 2.0}\n",
            "{'loss': 1.9219, 'grad_norm': 132.93368530273438, 'learning_rate': 3.965873836608066e-05, 'epoch': 2.0682523267838677}\n",
            "{'loss': 1.5393, 'grad_norm': 0.05358123779296875, 'learning_rate': 3.879696656325405e-05, 'epoch': 2.24060668734919}\n",
            "{'loss': 1.6745, 'grad_norm': 89.65274810791016, 'learning_rate': 3.793519476042744e-05, 'epoch': 2.412961047914512}\n",
            "{'loss': 1.6613, 'grad_norm': 164.5702667236328, 'learning_rate': 3.707342295760083e-05, 'epoch': 2.5853154084798344}\n",
            "{'loss': 1.7597, 'grad_norm': 65.85718536376953, 'learning_rate': 3.621165115477422e-05, 'epoch': 2.757669769045157}\n",
            "{'loss': 1.6269, 'grad_norm': 0.472781777381897, 'learning_rate': 3.5349879351947605e-05, 'epoch': 2.930024129610479}\n",
            "{'eval_loss': 2.8095717430114746, 'eval_runtime': 3.4727, 'eval_samples_per_second': 185.157, 'eval_steps_per_second': 185.157, 'epoch': 3.0}\n",
            "{'loss': 1.3039, 'grad_norm': 14.456855773925781, 'learning_rate': 3.4488107549120996e-05, 'epoch': 3.1023784901758016}\n",
            "{'loss': 1.2907, 'grad_norm': 0.004825249779969454, 'learning_rate': 3.3626335746294386e-05, 'epoch': 3.274732850741124}\n",
            "{'loss': 1.3605, 'grad_norm': 44.1312255859375, 'learning_rate': 3.276456394346777e-05, 'epoch': 3.447087211306446}\n",
            "{'loss': 1.313, 'grad_norm': 0.011788727715611458, 'learning_rate': 3.190279214064116e-05, 'epoch': 3.6194415718717683}\n",
            "{'loss': 1.3539, 'grad_norm': 111.74198913574219, 'learning_rate': 3.1041020337814545e-05, 'epoch': 3.7917959324370907}\n",
            "{'loss': 1.3736, 'grad_norm': 14.806769371032715, 'learning_rate': 3.0179248534987936e-05, 'epoch': 3.964150293002413}\n",
            "{'eval_loss': 3.71575927734375, 'eval_runtime': 3.4897, 'eval_samples_per_second': 184.257, 'eval_steps_per_second': 184.257, 'epoch': 4.0}\n",
            "{'loss': 1.1337, 'grad_norm': 0.2798398733139038, 'learning_rate': 2.9317476732161327e-05, 'epoch': 4.1365046535677354}\n",
            "{'loss': 0.8832, 'grad_norm': 0.000381304940674454, 'learning_rate': 2.8455704929334714e-05, 'epoch': 4.308859014133057}\n",
            "{'loss': 1.0429, 'grad_norm': 0.026021480560302734, 'learning_rate': 2.7593933126508105e-05, 'epoch': 4.48121337469838}\n",
            "{'loss': 1.05, 'grad_norm': 0.042143967002630234, 'learning_rate': 2.6732161323681492e-05, 'epoch': 4.653567735263702}\n",
            "{'loss': 1.2204, 'grad_norm': 1.0886622667312622, 'learning_rate': 2.5870389520854876e-05, 'epoch': 4.825922095829024}\n",
            "{'loss': 1.0346, 'grad_norm': 59.51507568359375, 'learning_rate': 2.5008617718028267e-05, 'epoch': 4.998276456394347}\n",
            "{'eval_loss': 3.721050262451172, 'eval_runtime': 3.5265, 'eval_samples_per_second': 182.333, 'eval_steps_per_second': 182.333, 'epoch': 5.0}\n",
            "{'loss': 0.7455, 'grad_norm': 0.0031452092807739973, 'learning_rate': 2.4146845915201654e-05, 'epoch': 5.170630816959669}\n",
            "{'loss': 0.6839, 'grad_norm': 14.211149215698242, 'learning_rate': 2.3285074112375045e-05, 'epoch': 5.342985177524992}\n",
            "{'loss': 0.9094, 'grad_norm': 0.04448175057768822, 'learning_rate': 2.2423302309548433e-05, 'epoch': 5.515339538090314}\n",
            "{'loss': 0.7253, 'grad_norm': 85.01522064208984, 'learning_rate': 2.1561530506721823e-05, 'epoch': 5.6876938986556365}\n",
            "{'loss': 0.9324, 'grad_norm': 0.006590443663299084, 'learning_rate': 2.0699758703895207e-05, 'epoch': 5.860048259220958}\n",
            "{'eval_loss': 5.0420050621032715, 'eval_runtime': 3.4739, 'eval_samples_per_second': 185.096, 'eval_steps_per_second': 185.096, 'epoch': 6.0}\n",
            "{'loss': 0.6782, 'grad_norm': 0.00025732911308296025, 'learning_rate': 1.9837986901068598e-05, 'epoch': 6.03240261978628}\n",
            "{'loss': 0.4515, 'grad_norm': 0.0002719809126574546, 'learning_rate': 1.8976215098241985e-05, 'epoch': 6.204756980351603}\n",
            "{'loss': 0.4765, 'grad_norm': 0.00026924125268124044, 'learning_rate': 1.8114443295415376e-05, 'epoch': 6.377111340916925}\n",
            "{'loss': 0.6736, 'grad_norm': 211.07669067382812, 'learning_rate': 1.7252671492588764e-05, 'epoch': 6.549465701482248}\n",
            "{'loss': 0.5743, 'grad_norm': 0.09223338216543198, 'learning_rate': 1.639089968976215e-05, 'epoch': 6.72182006204757}\n",
            "{'loss': 0.6622, 'grad_norm': 0.02522237040102482, 'learning_rate': 1.5529127886935542e-05, 'epoch': 6.894174422612892}\n",
            "{'eval_loss': 5.889535903930664, 'eval_runtime': 3.4667, 'eval_samples_per_second': 185.479, 'eval_steps_per_second': 185.479, 'epoch': 7.0}\n",
            "{'loss': 0.5225, 'grad_norm': 0.0010715887183323503, 'learning_rate': 1.466735608410893e-05, 'epoch': 7.066528783178215}\n",
            "{'loss': 0.3396, 'grad_norm': 0.02251248247921467, 'learning_rate': 1.3805584281282317e-05, 'epoch': 7.238883143743537}\n",
            "{'loss': 0.3173, 'grad_norm': 0.0012776665389537811, 'learning_rate': 1.2943812478455706e-05, 'epoch': 7.411237504308859}\n",
            "{'loss': 0.4137, 'grad_norm': 0.002394856419414282, 'learning_rate': 1.2082040675629095e-05, 'epoch': 7.583591864874181}\n",
            "{'loss': 0.4531, 'grad_norm': 1.4660760164260864, 'learning_rate': 1.1220268872802482e-05, 'epoch': 7.755946225439503}\n",
            "{'loss': 0.3714, 'grad_norm': 0.006613635923713446, 'learning_rate': 1.0358497069975871e-05, 'epoch': 7.928300586004826}\n",
            "{'eval_loss': 6.597111701965332, 'eval_runtime': 3.4604, 'eval_samples_per_second': 185.816, 'eval_steps_per_second': 185.816, 'epoch': 8.0}\n",
            "{'loss': 0.3121, 'grad_norm': 0.0019535869359970093, 'learning_rate': 9.496725267149259e-06, 'epoch': 8.100654946570149}\n",
            "{'loss': 0.1297, 'grad_norm': 177.0584259033203, 'learning_rate': 8.634953464322648e-06, 'epoch': 8.273009307135471}\n",
            "{'loss': 0.2207, 'grad_norm': 0.0001565011334605515, 'learning_rate': 7.773181661496037e-06, 'epoch': 8.445363667700793}\n",
            "{'loss': 0.289, 'grad_norm': 0.0017099272226914763, 'learning_rate': 6.911409858669425e-06, 'epoch': 8.617718028266115}\n",
            "{'loss': 0.2314, 'grad_norm': 0.012083498761057854, 'learning_rate': 6.049638055842813e-06, 'epoch': 8.790072388831437}\n",
            "{'loss': 0.3121, 'grad_norm': 0.0004932334995828569, 'learning_rate': 5.187866253016201e-06, 'epoch': 8.96242674939676}\n",
            "{'eval_loss': 6.686398029327393, 'eval_runtime': 3.5077, 'eval_samples_per_second': 183.309, 'eval_steps_per_second': 183.309, 'epoch': 9.0}\n",
            "{'loss': 0.1076, 'grad_norm': 0.018392521888017654, 'learning_rate': 4.32609445018959e-06, 'epoch': 9.134781109962082}\n",
            "{'loss': 0.1169, 'grad_norm': 0.0029485239647328854, 'learning_rate': 3.4643226473629783e-06, 'epoch': 9.307135470527404}\n",
            "{'loss': 0.1349, 'grad_norm': 0.12416242063045502, 'learning_rate': 2.602550844536367e-06, 'epoch': 9.479489831092726}\n",
            "{'loss': 0.1745, 'grad_norm': 80.20246124267578, 'learning_rate': 1.7407790417097554e-06, 'epoch': 9.651844191658048}\n",
            "{'loss': 0.0674, 'grad_norm': 0.0004967843997292221, 'learning_rate': 8.790072388831437e-07, 'epoch': 9.824198552223372}\n",
            "{'loss': 0.1312, 'grad_norm': 16.915185928344727, 'learning_rate': 1.723543605653223e-08, 'epoch': 9.996552912788694}\n",
            "{'eval_loss': 7.50164794921875, 'eval_runtime': 3.4759, 'eval_samples_per_second': 184.985, 'eval_steps_per_second': 184.985, 'epoch': 10.0}\n",
            "{'train_runtime': 1219.452, 'train_samples_per_second': 23.789, 'train_steps_per_second': 23.789, 'train_loss': 1.0760263618601587, 'epoch': 10.0}\n",
            "model ru-bert train time 0:20:19.573845\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 643/643 [00:01<00:00, 375.42it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "model ru-bert invalid f1 score 1.0890405705959045\n",
            "model ru-bert squad results {'exact': 19.440124416796266, 'f1': 46.1715410185963, 'total': 643, 'HasAns_exact': 19.440124416796266, 'HasAns_f1': 46.1715410185963, 'HasAns_total': 643, 'best_exact': 19.440124416796266, 'best_exact_thresh': 0.0, 'best_f1': 46.1715410185963, 'best_f1_thresh': 0.0}\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForQuestionAnswering, DefaultDataCollator, TrainingArguments, Trainer\n",
        "import torch\n",
        "import collections\n",
        "from datetime import datetime\n",
        "from tqdm import tqdm\n",
        "from evaluate import load\n",
        "from transformers.utils.logging import set_verbosity_error\n",
        "from transformers import set_seed\n",
        "\n",
        "set_seed(42)\n",
        "\n",
        "set_verbosity_error()\n",
        "squad_v2_metric = load(\"squad_v2\")\n",
        "\n",
        "val_answers = [a['text'][0] for a in squad['validation']['answers']]\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "train_times = {}\n",
        "for batch, lr, epochs, model_name, model_path in [\n",
        "    (1, 3e-5, 10, 'm-bert', 'bert-base-multilingual-cased'),\n",
        "    (1, 1e-5, 20, 'm-distil-bert', 'distilbert/distilbert-base-multilingual-cased'),\n",
        "    (1, 3e-5, 10, 'xlm-roberta', 'FacebookAI/xlm-roberta-base'),\n",
        "    (1, 5e-5, 10, 'ru-bert', 'DeepPavlov/rubert-base-cased'),\n",
        "]:\n",
        "    model = AutoModelForQuestionAnswering.from_pretrained(model_path)\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "\n",
        "    tokenized_datasets = squad.map(prepare_train_features, batched=True, remove_columns=squad[\"train\"].column_names)\n",
        "\n",
        "    with open(f\"../data/tokenized_{model_name}_datasets.pkl\",\"wb\") as file:\n",
        "        pickle.dump(tokenized_datasets, file)\n",
        "\n",
        "\n",
        "    args = TrainingArguments(\n",
        "        output_dir=f\"../models/{model_name}\",\n",
        "        evaluation_strategy = \"epoch\",\n",
        "        save_strategy=\"epoch\", \n",
        "        learning_rate=lr,\n",
        "        per_device_train_batch_size=batch,\n",
        "        per_device_eval_batch_size=batch,\n",
        "        num_train_epochs=epochs,\n",
        "        report_to='tensorboard',\n",
        "        logging_dir=f'../logs/{model_name}',\n",
        "        load_best_model_at_end=True,\n",
        "        # weight_decay=0.01,\n",
        "    )\n",
        "\n",
        "\n",
        "    data_collator = DefaultDataCollator()\n",
        "\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        args=args,\n",
        "        train_dataset=tokenized_datasets[\"train\"],\n",
        "        eval_dataset=tokenized_datasets[\"validation\"],\n",
        "        data_collator=data_collator,\n",
        "        tokenizer=tokenizer,\n",
        "    )\n",
        "\n",
        "    start_time = datetime.now()\n",
        "    trainer.train()\n",
        "    print(\"model\", model_name, \"train time\", datetime.now() - start_time)\n",
        "    train_times[model_name] = datetime.now() - start_time\n",
        "\n",
        "    trainer.save_model()\n",
        "\n",
        "    eval_answers = []\n",
        "\n",
        "    for instance in tqdm(squad['validation']):\n",
        "        context = instance['context']\n",
        "        question = instance['question']\n",
        "\n",
        "        given_answer = instance['answers']['text'][0]  # Assuming the first answer is the correct one\n",
        "\n",
        "        inputs = tokenizer(question, context, return_tensors='pt', max_length=512, truncation=True)\n",
        "\n",
        "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "\n",
        "        with torch.no_grad():\n",
        "            output = model(**inputs)\n",
        "    \n",
        "        start_idx = torch.argmax(output.start_logits)\n",
        "        end_idx = torch.argmax(output.end_logits)\n",
        "\n",
        "        predicted_answer = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(inputs['input_ids'][0][start_idx:end_idx + 1]))\n",
        "\n",
        "        eval_answers.append(predicted_answer)\n",
        "\n",
        "    num_c = []\n",
        "    num_p = []\n",
        "    num_g = []\n",
        "\n",
        "    for a in range(len(eval_answers)):\n",
        "\n",
        "        common = collections.Counter(eval_answers[a].split()) & collections.Counter(eval_answers[a].split()) # tokens shared between gold and predicted answers\n",
        "        num_common = sum(common.values())\n",
        "\n",
        "        num_pred = len(str(eval_answers[a]).split()) # the number of predicted tokens\n",
        "\n",
        "        num_gold = len(str(val_answers[a]).split()) # the number of gold tokens\n",
        "\n",
        "        num_c.append(num_common)\n",
        "        num_p.append(num_pred)\n",
        "        num_g.append(num_gold)\n",
        "\n",
        "    precision = 1.0 * sum(num_c) / sum(num_p) # the num of tokens shared between gold and predicted answers / the num of predicted tokens\n",
        "    recall = 1.0 * sum(num_c) / sum(num_g) # the num of tokens shared between gold and predicted answers / the num of gold tokens\n",
        "    invalid_f1_score= (2 * precision * recall) / (precision + recall)\n",
        "    print(\"model\", model_name, \"invalid f1 score\", invalid_f1_score)\n",
        "\n",
        "    predictions = [{'prediction_text': a, 'id': str(idx), 'no_answer_probability': 0.} for idx, a in enumerate(eval_answers)]\n",
        "    references = [{'answers': a, 'id': str(idx)} for idx, a in enumerate(squad['validation']['answers'])]\n",
        "\n",
        "    results = squad_v2_metric.compute(predictions=predictions, references=references)\n",
        "    print(\"model\", model_name, \"squad results\", results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'m-bert': datetime.timedelta(seconds=1193, microseconds=289239),\n",
              " 'm-distil-bert': datetime.timedelta(seconds=1662, microseconds=582986),\n",
              " 'xlm-roberta': datetime.timedelta(seconds=1657, microseconds=153528),\n",
              " 'ru-bert': datetime.timedelta(seconds=1219, microseconds=573860)}"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_times"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Map: 100%|██████████| 2901/2901 [00:00<00:00, 7774.74 examples/s]\n",
            "Map: 100%|██████████| 643/643 [00:00<00:00, 7263.40 examples/s]\n",
            "100%|██████████| 643/643 [00:01<00:00, 343.68it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "model m-bert invalid f1 score 0.9771807457160079\n",
            "model m-bert squad results {'exact': 21.15085536547434, 'f1': 47.424322555144975, 'total': 643, 'HasAns_exact': 21.15085536547434, 'HasAns_f1': 47.424322555144975, 'HasAns_total': 643, 'best_exact': 21.15085536547434, 'best_exact_thresh': 0.0, 'best_f1': 47.424322555144975, 'best_f1_thresh': 0.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Map: 100%|██████████| 2901/2901 [00:00<00:00, 8806.45 examples/s]\n",
            "Map: 100%|██████████| 643/643 [00:00<00:00, 9177.85 examples/s]\n",
            "100%|██████████| 643/643 [00:01<00:00, 472.01it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "model m-distil-bert invalid f1 score 1.1547110731568462\n",
            "model m-distil-bert squad results {'exact': 17.418351477449455, 'f1': 49.03699913975556, 'total': 643, 'HasAns_exact': 17.418351477449455, 'HasAns_f1': 49.03699913975556, 'HasAns_total': 643, 'best_exact': 17.418351477449455, 'best_exact_thresh': 0.0, 'best_f1': 49.03699913975556, 'best_f1_thresh': 0.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Map: 100%|██████████| 2901/2901 [00:00<00:00, 6590.98 examples/s]\n",
            "Map: 100%|██████████| 643/643 [00:00<00:00, 8510.16 examples/s]\n",
            "100%|██████████| 643/643 [00:01<00:00, 342.80it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "model xlm-roberta invalid f1 score 1.0327361563517916\n",
            "model xlm-roberta squad results {'exact': 23.17262830482115, 'f1': 47.158801493964475, 'total': 643, 'HasAns_exact': 23.17262830482115, 'HasAns_f1': 47.158801493964475, 'HasAns_total': 643, 'best_exact': 23.17262830482115, 'best_exact_thresh': 0.0, 'best_f1': 47.158801493964475, 'best_f1_thresh': 0.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Map: 100%|██████████| 2901/2901 [00:00<00:00, 7950.03 examples/s]\n",
            "Map: 100%|██████████| 643/643 [00:00<00:00, 7774.24 examples/s]\n",
            "100%|██████████| 643/643 [00:01<00:00, 388.67it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "model ru-bert invalid f1 score 1.0890405705959045\n",
            "model ru-bert squad results {'exact': 19.440124416796266, 'f1': 46.1715410185963, 'total': 643, 'HasAns_exact': 19.440124416796266, 'HasAns_f1': 46.1715410185963, 'HasAns_total': 643, 'best_exact': 19.440124416796266, 'best_exact_thresh': 0.0, 'best_f1': 46.1715410185963, 'best_f1_thresh': 0.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "for model_name in ['m-bert', 'm-distil-bert', 'xlm-roberta', 'ru-bert']:\n",
        "\n",
        "    model = AutoModelForQuestionAnswering.from_pretrained(f\"../models/{model_name}\").cuda()\n",
        "    tokenizer = AutoTokenizer.from_pretrained(f\"../models/{model_name}\")\n",
        "\n",
        "    tokenized_datasets = squad.map(prepare_train_features, batched=True, remove_columns=squad[\"train\"].column_names)\n",
        "\n",
        "    eval_answers = []\n",
        "\n",
        "    for instance in tqdm(squad['validation']):\n",
        "        context = instance['context']\n",
        "        question = instance['question']\n",
        "\n",
        "        given_answer = instance['answers']['text'][0]  # Assuming the first answer is the correct one\n",
        "\n",
        "        inputs = tokenizer(question, context, return_tensors='pt', max_length=512, truncation=True)\n",
        "\n",
        "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "\n",
        "        with torch.no_grad():\n",
        "            output = model(**inputs)\n",
        "    \n",
        "        start_idx = torch.argmax(output.start_logits)\n",
        "        end_idx = torch.argmax(output.end_logits)\n",
        "\n",
        "        predicted_answer = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(inputs['input_ids'][0][start_idx:end_idx + 1]))\n",
        "\n",
        "        eval_answers.append(predicted_answer)\n",
        "\n",
        "    num_c = []\n",
        "    num_p = []\n",
        "    num_g = []\n",
        "\n",
        "    for a in range(len(eval_answers)):\n",
        "\n",
        "        common = collections.Counter(eval_answers[a].split()) & collections.Counter(eval_answers[a].split()) # tokens shared between gold and predicted answers\n",
        "        num_common = sum(common.values())\n",
        "\n",
        "        num_pred = len(str(eval_answers[a]).split()) # the number of predicted tokens\n",
        "\n",
        "        num_gold = len(str(val_answers[a]).split()) # the number of gold tokens\n",
        "\n",
        "        num_c.append(num_common)\n",
        "        num_p.append(num_pred)\n",
        "        num_g.append(num_gold)\n",
        "\n",
        "    precision = 1.0 * sum(num_c) / sum(num_p) # the num of tokens shared between gold and predicted answers / the num of predicted tokens\n",
        "    recall = 1.0 * sum(num_c) / sum(num_g) # the num of tokens shared between gold and predicted answers / the num of gold tokens\n",
        "    invalid_f1_score= (2 * precision * recall) / (precision + recall)\n",
        "    print(\"model\", model_name, \"invalid f1 score\", invalid_f1_score)\n",
        "\n",
        "    predictions = [{'prediction_text': a, 'id': str(idx), 'no_answer_probability': 0.} for idx, a in enumerate(eval_answers)]\n",
        "    references = [{'answers': a, 'id': str(idx)} for idx, a in enumerate(squad['validation']['answers'])]\n",
        "\n",
        "    results = squad_v2_metric.compute(predictions=predictions, references=references)\n",
        "    print(\"model\", model_name, \"squad results\", results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "import gc\n",
        "import torch\n",
        "\n",
        "del model\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loading checkpoint shards: 100%|██████████| 6/6 [00:01<00:00,  3.38it/s]\n",
            "WARNING:root:Some parameters are on the meta device device because they were offloaded to the cpu.\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import json\n",
        "import os.path\n",
        "import pickle\n",
        "from tqdm import tqdm\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, pipeline\n",
        "\n",
        "TRANSLATION_MODEL = 'Unbabel/TowerInstruct-v0.1'\n",
        "TRANSLATION_MODEL_CACHE = TRANSLATION_MODEL + '_substring_logic'\n",
        "# TRANSLATION_MODEL = 'facebook/nllb-200-3.3B'\n",
        "\n",
        "if 'nllb' in TRANSLATION_MODEL:\n",
        "    model = AutoModelForSeq2SeqLM.from_pretrained(TRANSLATION_MODEL, device_map=\"auto\")\n",
        "    tokenizer = AutoTokenizer.from_pretrained(TRANSLATION_MODEL)\n",
        "\n",
        "    pipe = pipeline('translation', model=model, tokenizer=tokenizer, src_lang='rus_Cyrl', tgt_lang='eng_Latn',\n",
        "                    max_length=1024, device_map=\"auto\")\n",
        "else:\n",
        "    pipe = pipeline(\"text-generation\", model=TRANSLATION_MODEL, torch_dtype=torch.bfloat16, device_map=\"auto\")\n",
        "\n",
        "if os.path.exists('../data/translation_cache.json'):\n",
        "    with open('../data/translation_cache.json', 'r', encoding='utf-8') as translation_f:\n",
        "        TRANSLATION_CACHE = json.loads(translation_f.read() or '{}')\n",
        "        TRANSLATION_CACHE[TRANSLATION_MODEL] = TRANSLATION_CACHE.get(TRANSLATION_MODEL, {})\n",
        "        TRANSLATION_CACHE[TRANSLATION_MODEL_CACHE] = TRANSLATION_CACHE.get(TRANSLATION_MODEL_CACHE, {})\n",
        "else:\n",
        "    TRANSLATION_CACHE = {TRANSLATION_MODEL: {}, TRANSLATION_MODEL_CACHE: {}}\n",
        "\n",
        "SPLIT_BY = '\\nEnglish:<|im_end|>\\n<|im_start|>assistant\\n'\n",
        "\n",
        "\n",
        "def fix_translation(in_text):\n",
        "    return in_text[in_text.find(SPLIT_BY) + len(SPLIT_BY):]\n",
        "\n",
        "\n",
        "def translate(input_txt):\n",
        "    if TRANSLATION_CACHE[TRANSLATION_MODEL_CACHE].get(input_txt):\n",
        "        return TRANSLATION_CACHE[TRANSLATION_MODEL_CACHE][input_txt]\n",
        "    if not input_txt:\n",
        "        return input_txt\n",
        "\n",
        "    # Prefer replacing long sequence over small\n",
        "    for russian_source in sorted(TRANSLATION_CACHE[TRANSLATION_MODEL_CACHE].keys(), key=lambda k: len(k), reverse=True):\n",
        "        # if russian_source in out_text:\n",
        "        out_text = input_txt.replace(russian_source, TRANSLATION_CACHE[TRANSLATION_MODEL_CACHE][russian_source])\n",
        "    if 'nllb' in TRANSLATION_MODEL_CACHE:\n",
        "        outputs = _nllb_translate(input_txt)\n",
        "    else:\n",
        "        outputs = _tower_translate(input_txt)\n",
        "        outputs = fix_translation(outputs[0][\"generated_text\"])\n",
        "\n",
        "    TRANSLATION_CACHE[TRANSLATION_MODEL_CACHE][input_txt] = outputs\n",
        "    with open('../data/translation_cache.json', 'w', encoding='utf-8') as translation_f:\n",
        "        translation_f.write(json.dumps(TRANSLATION_CACHE, indent=4, ensure_ascii=False))\n",
        "    return TRANSLATION_CACHE[TRANSLATION_MODEL_CACHE][input_txt]\n",
        "\n",
        "\n",
        "def _nllb_translate(input_txt):\n",
        "    output = pipe(input_txt)\n",
        "    return output[0]['translation_text']\n",
        "\n",
        "\n",
        "def _tower_translate(input_txt):\n",
        "    messages = [{\n",
        "        \"role\": \"user\",\n",
        "        \"content\": f\"Translate the following text from Russian into English.\\nRussian: {input_txt}\\nEnglish:\"\n",
        "    }, ]\n",
        "    prompt = pipe.tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
        "    outputs = pipe(prompt, max_new_tokens=512, do_sample=False)\n",
        "    return outputs\n",
        "\n",
        "\n",
        "original_ds = pickle.loads(open(\"../data/squad_dataset.pkl\",\"rb\").read())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Map: 100%|██████████| 2901/2901 [01:05<00:00, 44.53 examples/s]\n",
            "Map: 100%|██████████| 643/643 [00:09<00:00, 66.97 examples/s] \n"
          ]
        }
      ],
      "source": [
        "def translate_record(record):      \n",
        "    record['answers']['text_en'] = [translate(t) for t in record['answers']['text']]\n",
        "    record['context_en'] = ''\n",
        "    last_idx = 0\n",
        "    for i in range(len(record['answers']['text_en'])):\n",
        "        record['context_en'] += translate(record['context'][last_idx:record['context'].find(record['answers']['text'][i])])\n",
        "        record['context_en'] += ' ' + record['answers']['text_en'][i]\n",
        "        last_idx = record['context'].find(record['answers']['text'][i]) + len(record['answers']['text_en'][i])\n",
        "\n",
        "    record['context_en'] += translate(record['context'][last_idx:])\n",
        "    record['question_en'] = translate(record['question'])\n",
        "    \n",
        "    record['answers']['answer_start_en'] = []\n",
        "    for i in range(len(record['answers']['text'])):\n",
        "        if record['answers']['text_en'][i] not in record['context_en']:\n",
        "            invalid_counter += 1\n",
        "            record['answers']['answer_start_en'].append(0)\n",
        "        else:\n",
        "            record['answers']['answer_start_en'].append(record['context_en'].find(record['answers']['text_en'][i]))\n",
        "    return record\n",
        "\n",
        "for ds in ['train', 'validation']:\n",
        "    invalid_counter = 0\n",
        "    original_ds[ds] = original_ds[ds].map(translate_record)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Creating json from Arrow format: 100%|██████████| 3/3 [00:00<00:00, 68.75ba/s]\n",
            "Creating json from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 108.61ba/s]\n"
          ]
        }
      ],
      "source": [
        "for split, split_dataset in original_ds.items():\n",
        "    split_dataset.to_json(f'../data/translated_{TRANSLATION_MODEL_CACHE.replace(\"/\", \"_\")}_{split}.json', force_ascii=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyObSv3+ilrVHF5vItgMce1Q",
      "name": "Data_Preprocessor.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
